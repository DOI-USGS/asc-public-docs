{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduced Normal Equations\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Knoten\n",
    "\n",
    "An [Installation of Knoten](https://github.com/DOI-USGS/knoten/tree/main#installing) is requried.\n",
    "Most imports are included in the [knoten environment](https://github.com/DOI-USGS/knoten/blob/main/environment.yml).\n",
    "\n",
    "### ISIS\n",
    "An [installation of ISIS](https://astrogeology.usgs.gov/docs/how-to-guides/environment-setup-and-maintenance/installing-isis-via-anaconda/) and [ISIS-data](https://github.com/DOI-USGS/ISIS3?tab=readme-ov-file#full-isis-data-download) are also required.\n",
    "\n",
    "`ISISROOT` and `ISISDATA` must be set to point to your ISIS and ISIS-data installations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Kalasiris requires these to be set:\n",
    "os.environ['ISISROOT'] = '/usr/local/Caskroom/miniconda/base/envs/isis-prod'\n",
    "os.environ['ISISDATA'] = '/Volumes/usgs-data/isis-data'\n",
    "\n",
    "from subprocess import CalledProcessError\n",
    "import urllib.request\n",
    "\n",
    "import kalasiris as isis\n",
    "from plio.io import io_controlnetwork\n",
    "from knoten.bundle import *\n",
    "\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "\n",
    "imgurl = [\n",
    "    'https://planetarydata.jpl.nasa.gov/img/data/mro/mars_reconnaissance_orbiter/ctx/mrox_2130/data/F02_036648_2021_XN_22N022W.IMG',\n",
    "    'https://planetarydata.jpl.nasa.gov/img/data/mro/mars_reconnaissance_orbiter/ctx/mrox_2281/data/F06_038336_2024_XN_22N022W.IMG',\n",
    "    'https://planetarydata.jpl.nasa.gov/img/data/mro/mars_reconnaissance_orbiter/ctx/mrox_2479/data/F22_044336_2020_XN_22N022W.IMG',\n",
    "    'https://planetarydata.jpl.nasa.gov/img/data/mro/mars_reconnaissance_orbiter/ctx/mrox_2741/data/J07_047448_2024_XN_22N022W.IMG',\n",
    "]\n",
    "\n",
    "image_dir = 'data'\n",
    "imgfile = [ os.path.join(image_dir, os.path.basename(url)) for url in imgurl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Files\n",
    "\n",
    "downloader = urllib.request.URLopener()\n",
    "\n",
    "for url, file in zip(imgurl, imgfile):\n",
    "    if not os.path.isfile(file):\n",
    "        downloader.retrieve(url, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import into ISIS and SpiceInit\n",
    "\n",
    "cubfile = [os.path.splitext(img)[0] + '.cal.cub' for img in imgfile]\n",
    "\n",
    "try:\n",
    "    for img, cub in zip(imgfile, cubfile):\n",
    "        isis.mroctx2isis(img, to=cub)\n",
    "except CalledProcessError as e:\n",
    "    print('MROCTX2ISIS ' + e.stderr)\n",
    "\n",
    "try:\n",
    "    for cub in cubfile:\n",
    "        isis.spiceinit(cub)\n",
    "except CalledProcessError as e:\n",
    "    print('SPICEINIT ' + e.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/knoten/lib/python3.12/site-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cubes = 'data/cubes.lis'\n",
    "sensors = generate_sensors(cubes)\n",
    "\n",
    "network = 'data/hand_dense.net'\n",
    "cnet = io_controlnetwork.from_isis(network)\n",
    "sensors = {sn: sensors[sn] for sn in cnet[\"serialnumber\"].unique()}\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # autoseed did not generate ground points, calculate and repopulate the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: MRO/CTX/1085197697:073\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n",
      "Image: MRO/CTX/1157902986:250\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n",
      "Image: MRO/CTX/1096561308:045\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n",
      "Image: MRO/CTX/1136952576:186\n",
      "  IT Pos. Bias    | 0 | 0.0\n",
      "  CT Pos. Bias    | 1 | 0.0\n",
      "  Rad Pos. Bias   | 2 | 0.0\n",
      "  IT Vel. Bias    | 3 | 0.0\n",
      "  CT Vel. Bias    | 4 | 0.0\n",
      "  Rad Vel. Bias   | 5 | 0.0\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "  Omega Accl      | 12 | 0.0\n",
      "  Phi Accl        | 13 | 0.0\n",
      "  Kappa Accl      | 14 | 0.0\n",
      "  Focal Bias      | 15 | 0.0\n"
     ]
    }
   ],
   "source": [
    "all_parameters = {sn: get_sensor_parameters(sensor) for sn, sensor in sensors.items()}\n",
    "for sn, parameters in all_parameters.items():\n",
    "    print(f\"Image: {sn}\")\n",
    "    for param in parameters:\n",
    "        print(f\"  {param.name} | {param.index} | {param.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: MRO/CTX/1085197697:073\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "Image: MRO/CTX/1157902986:250\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "Image: MRO/CTX/1096561308:045\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n",
      "Image: MRO/CTX/1136952576:186\n",
      "  Omega Bias      | 6 | 0.0\n",
      "  Phi Bias        | 7 | 0.0\n",
      "  Kappa Bias      | 8 | 0.0\n",
      "  Omega Rate      | 9 | 0.0\n",
      "  Phi Rate        | 10 | 0.0\n",
      "  Kappa Rate      | 11 | 0.0\n"
     ]
    }
   ],
   "source": [
    "# Solve for angles and angular rates\n",
    "solve_parameters = {sn: params[6:12] for sn, params in all_parameters.items()}\n",
    "for sn, parameters in solve_parameters.items():\n",
    "    print(f\"Image: {sn}\")\n",
    "    for param in parameters:\n",
    "        print(f\"  {param.name} | {param.index} | {param.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_dict = compute_coefficient_columns(cnet, sensors, solve_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations = 2 * len(cnet)\n",
    "W_observations = np.eye(num_observations) # this is a place holder until Jesse adds his calculations\n",
    "W_params = compute_parameter_weights(cnet, sensors, solve_parameters, column_dict)\n",
    "dof = W_observations.shape[0] - W_params.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10\n",
    "tol = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sensor_params = sum([len(parameters) for parameters in solve_parameters.values()])\n",
    "num_point_params = 3 * len(cnet[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: sigma0 = 3.386510411078402\n",
      "\n",
      "corrections: mean = 0.02519442538434387 min = -26.658758524079243 max = 19.405572382862808\n",
      "iteration 1: sigma0 = 0.8522450273089555\n",
      "\n",
      "corrections: mean = 6.867275520848591e-05 min = -0.004864950076602206 max = 0.005917455724117964\n",
      "iteration 2: sigma0 = 0.6410740414243817\n",
      "\n",
      "corrections: mean = 1.8372002331067272e-08 min = -6.441777911409558e-07 max = 1.5574705798002814e-06\n",
      "iteration 3: sigma0 = 0.6410739981011393\n",
      "\n",
      "corrections: mean = -1.5960753684616694e-11 min = -8.058440895871958e-10 max = 8.864516184747238e-10\n",
      "iteration 4: sigma0 = 0.64107399810154\n",
      "\n",
      "change in sigma0 of 4.00679489587219e-13 converged!\n"
     ]
    }
   ],
   "source": [
    "sensors = generate_sensors(cubes) # generate sensors\n",
    "cnet = io_controlnetwork.from_isis(network) # load in network\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # calculate ground points\n",
    "\n",
    "column_dict = compute_coefficient_columns(cnet, sensors, solve_parameters)\n",
    "num_parameters = max(col_range[1] for col_range in column_dict.values())\n",
    "num_observations = 2 * len(cnet)\n",
    "W_observations = np.eye(num_observations)\n",
    "W_params = compute_parameter_weights(cnet, sensors, solve_parameters, column_dict)\n",
    "\n",
    "iteration = 0\n",
    "V = compute_residuals(cnet, sensors)\n",
    "dX = np.zeros(W_params.shape[0]) #initialize for sigma calculatioN\n",
    "sigma0 = compute_sigma0(V, dX, W_params, W_observations)\n",
    "print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "\n",
    "total_correction_dense = np.zeros(num_parameters)\n",
    "for i in range(max_iterations):   \n",
    "    iteration += 1\n",
    "    old_sigma0 = sigma0\n",
    "    \n",
    "    J = compute_jacobian(cnet, sensors, solve_parameters, column_dict)    \n",
    "    N = J.T.dot(W_observations).dot(J) + W_params # calculate the normal equation\n",
    "    C = J.T.dot(W_observations).dot(V) - W_params.dot(total_correction_dense)\n",
    "    dX = np.linalg.inv(N).dot(C) #calculate change in camera parameters and ground points\n",
    "    total_correction_dense += dX\n",
    "    print(f'corrections: mean = {dX.mean()} min = {dX.min()} max = {dX.max()}')\n",
    "    \n",
    "    update_parameters(sensors, solve_parameters, cnet, dX, column_dict)\n",
    "    \n",
    "    V = compute_residuals(cnet, sensors)\n",
    "    sigma0 = compute_sigma0(V, dX, W_params, W_observations)\n",
    "    sigma0 = np.sqrt((V.dot(W_observations).dot(V) + dX.dot(W_params).dot(dX))/dof)\n",
    "    print(f'iteration {iteration}: sigma0 = {sigma0}\\n')\n",
    "    \n",
    "    if (abs(sigma0 - old_sigma0) < tol):\n",
    "        print(f'change in sigma0 of {abs(sigma0 - old_sigma0)} converged!')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrections: mean = 0.02519442538434383 min = -26.65875852407914 max = 19.40557238286281\n",
      "iteration 1: sigma0 = 0.8522450273105413\n",
      "\n",
      "corrections: mean = 6.86727606479218e-05 min = -0.004864950150258623 max = 0.005917455863802144\n"
     ]
    },
    
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2: sigma0 = 0.64107404140547\n",
      "\n",
      "corrections: mean = 1.8352119712705532e-08 min = -6.442099360416587e-07 max = 1.5574976963027463e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3: sigma0 = 0.641073998118407\n",
      "\n",
      "corrections: mean = 1.1279955347085866e-11 min = -1.0020180255690482e-09 max = 7.350010298342555e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4: sigma0 = 0.6410739980892225\n",
      "\n",
      "change in sigma0 of 2.918454367062395e-11 converged!\n"
     ]
    }
   ],
   "source": [
    "sensors = generate_sensors(cubes) # generate sensors\n",
    "cnet = io_controlnetwork.from_isis(network) # load in network\n",
    "cnet = compute_apriori_ground_points(cnet, sensors) # calculate ground points\n",
    "\n",
    "# This is setup once per bundle and then accumulates\n",
    "total_corrections = np.zeros(num_sensor_params + num_point_params)\n",
    "\n",
    "# These are computed once per bundle\n",
    "W_CC_sparse = sparse.csc_matrix((num_sensor_params, num_sensor_params))\n",
    "W_PP = {}\n",
    "\n",
    "# Compute image param weight matrices\n",
    "for sn, params in solve_parameters.items():\n",
    "    coeff_indices = column_dict[sn]\n",
    "    coeff_range = np.arange(coeff_indices[0], coeff_indices[1])\n",
    "    num_image_coeffs = coeff_indices[1] - coeff_indices[0]\n",
    "    W_CC_data = compute_image_weight(sensors[sn], params).ravel()\n",
    "    W_CC_row = np.repeat(coeff_range, num_image_coeffs)\n",
    "    W_CC_column = np.tile(coeff_range, num_image_coeffs)\n",
    "    W_CC_sparse += sparse.coo_matrix((W_CC_data, (W_CC_row, W_CC_column)), (num_sensor_params, num_sensor_params)).tocsc()\n",
    "    \n",
    "# Compute point param weight matrices\n",
    "for point_id in cnet['id'].unique():\n",
    "    W_PP[point_id] = compute_point_weight(cnet, point_id)\n",
    "    \n",
    "V = compute_residuals(cnet, sensors)\n",
    "sigma0 = compute_sigma0_sparse(V, np.zeros(total_corrections.shape), W_CC_sparse, W_PP, W_observations, column_dict)\n",
    "    \n",
    "# Start iteration logic\n",
    "for i in range(max_iterations):\n",
    "    old_sigma0 = sigma0\n",
    "    \n",
    "    H_CC_sparse = sparse.csc_matrix((num_sensor_params, num_sensor_params))\n",
    "    H_CC_sparse += W_CC_sparse\n",
    "\n",
    "    g_C_sparse = np.zeros(num_sensor_params)\n",
    "    g_C_sparse -= W_CC_sparse.dot(total_corrections[:num_sensor_params])\n",
    "    # g_C_sparse += W_CC_sparse.dot(sensor_corrections)\n",
    "\n",
    "    # Q = H_PP^-1 * H_PC \n",
    "    Q_mats = {}\n",
    "    # NIC = H_PP^-1 * g_P\n",
    "    NIC_vecs = {}\n",
    "\n",
    "    updates = np.zeros(num_sensor_params + num_point_params)\n",
    "\n",
    "    for point_id, group in cnet.groupby('id'):\n",
    "        ground_pt = group.iloc[0][[\"adjustedX\", \"adjustedY\", \"adjustedZ\"]]\n",
    "        H_CP = sparse.csc_matrix((num_sensor_params, 3))\n",
    "        H_PP = np.zeros((3, 3))\n",
    "        g_P = np.zeros(3)\n",
    "        for measure_idx, row in group.iterrows():\n",
    "            serial = row[\"serialnumber\"]\n",
    "            sensor = sensors[serial]\n",
    "            point_partials = compute_ground_partials(sensor, ground_pt)\n",
    "            sensor_partials = compute_sensor_partials(sensor, solve_parameters[serial], ground_pt)\n",
    "            coeff_indices = column_dict[serial]\n",
    "            coeff_range = np.arange(coeff_indices[0], coeff_indices[1])\n",
    "            num_image_coeffs = coeff_indices[1] - coeff_indices[0]\n",
    "\n",
    "            H_CC_point_data = np.dot(sensor_partials.T, sensor_partials).ravel()\n",
    "            H_CC_point_row = np.repeat(coeff_range, num_image_coeffs)\n",
    "            H_CC_point_column = np.tile(coeff_range, num_image_coeffs)\n",
    "            H_CC_sparse += sparse.coo_matrix((H_CC_point_data, (H_CC_point_row, H_CC_point_column)), (num_sensor_params, num_sensor_params)).tocsc()\n",
    "\n",
    "            H_CP_point_data = np.dot(sensor_partials.T, point_partials).ravel()\n",
    "            H_CP_point_row = np.repeat(coeff_range, 3)\n",
    "            H_CP_point_column = np.tile(np.arange(0, 3), num_image_coeffs)\n",
    "            H_CP += sparse.coo_matrix((H_CP_point_data, (H_CP_point_row, H_CP_point_column)), (num_sensor_params, 3)).tocsc()\n",
    "\n",
    "            H_PP += np.dot(point_partials.T, point_partials)\n",
    "\n",
    "            g_C_sparse[coeff_indices[0]:coeff_indices[1]] += np.dot(sensor_partials.T, V[2*measure_idx:2*measure_idx+2])\n",
    "            g_P += np.dot(point_partials.T, V[2*measure_idx:2*measure_idx+2])\n",
    "        point_param_range = column_dict[point_id]\n",
    "        g_P -= W_PP[point_id].dot(total_corrections[point_param_range[0]:point_param_range[1]])\n",
    "        H_PP += W_PP[point_id]\n",
    "        H_PP_inv = sparse.csc_matrix(np.linalg.inv(H_PP))\n",
    "        Q_mats[point_id] = H_PP_inv.dot(H_CP.transpose())\n",
    "        NIC_vecs[point_id] = H_PP_inv.dot(g_P)\n",
    "        H_CC_sparse -= H_CP.dot(Q_mats[point_id])\n",
    "        g_C_sparse -= H_CP.dot(NIC_vecs[point_id])\n",
    "\n",
    "    updates[:num_sensor_params] = sparse.linalg.spsolve(H_CC_sparse, g_C_sparse)\n",
    "\n",
    "    for point_id in Q_mats:\n",
    "        point_param_indices = column_dict[point_id]\n",
    "        updates[point_param_indices[0]:point_param_indices[1]] = NIC_vecs[point_id] - Q_mats[point_id].dot(updates[:num_sensor_params])\n",
    "        \n",
    "    print(f'corrections: mean = {updates.mean()} min = {updates.min()} max = {updates.max()}')\n",
    "\n",
    "    total_corrections += updates\n",
    "\n",
    "    update_parameters(sensors, solve_parameters, cnet, updates, column_dict)\n",
    "    V = compute_residuals(cnet, sensors)\n",
    "    sigma0 = compute_sigma0_sparse(V, updates, W_CC_sparse, W_PP, W_observations, column_dict)\n",
    "    print(f'iteration {i+1}: sigma0 = {sigma0}\\n')\n",
    "    \n",
    "    if (abs(sigma0 - old_sigma0) < tol):\n",
    "        print(f'change in sigma0 of {abs(sigma0 - old_sigma0)} converged!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor diff\n",
      "-8.027561948509288e-10\n",
      "1.0439631381586878e-09\n",
      "Point diff\n",
      "-3.0175491272377286e-10\n",
      "1.560850754200871e-10\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensor diff\")\n",
    "print(np.min(total_correction_dense[:num_sensor_params].flatten() - total_corrections[:num_sensor_params]))\n",
    "print(np.max(total_correction_dense[:num_sensor_params].flatten() - total_corrections[:num_sensor_params]))\n",
    "print(\"Point diff\")\n",
    "print(np.min(total_correction_dense[num_sensor_params:].flatten() - total_corrections[num_sensor_params:]))\n",
    "print(np.max(total_correction_dense[num_sensor_params:].flatten() - total_corrections[num_sensor_params:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
